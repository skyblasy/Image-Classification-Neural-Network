{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vH5X2ootLUK0"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RfjXeyx8Lh-1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import keras_preprocessing\n",
    "from keras_preprocessing import image\n",
    "from tensorflow.keras import layers\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense, Input\n",
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.metrics import Precision\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rw5BpINBL6T-"
   },
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if((logs.get('val_accuracy')>=0.9700) and (logs.get('val_precision')>=0.9775) and (logs.get('val_mae')<=0.0385)):\n",
    "      print(\"\\nReached 97% accuracy, 97.75% precision, and less than .0385 MAE, so cancelling training!\")\n",
    "      self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QLbyIb0rL7S1"
   },
   "outputs": [],
   "source": [
    "callbacks = myCallback()\n",
    "precision = Precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0PSvl4ETLk7O"
   },
   "outputs": [],
   "source": [
    "#This block gets the pre-trained model\n",
    "\n",
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
    "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
    "  \n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
    "                                include_top = False, \n",
    "                                weights = None)\n",
    "\n",
    "pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "for layer in pre_trained_model.layers:\n",
    "  layer.trainable = False\n",
    "  \n",
    "# pre_trained_model.summary()\n",
    "\n",
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bVOl1BDmLrHe"
   },
   "outputs": [],
   "source": [
    "!wget --no-check-certificate \\\n",
    "        https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
    "       -O /tmp/cats_and_dogs_filtered.zip\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "local_zip = '//tmp/cats_and_dogs_filtered.zip'\n",
    "\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "\n",
    "zip_ref.extractall('/tmp')\n",
    "zip_ref.close()\n",
    "\n",
    "# Define our example directories and files\n",
    "base_dir = '/tmp/cats_and_dogs_filtered'\n",
    "\n",
    "train_dir = os.path.join( base_dir, 'train')\n",
    "validation_dir = os.path.join( base_dir, 'validation')\n",
    "\n",
    "\n",
    "train_cats_dir = os.path.join(train_dir, 'cats') # Directory with our training cat pictures\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs') # Directory with our training dog pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats') # Directory with our validation cat pictures\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')# Directory with our validation dog pictures\n",
    "\n",
    "train_cat_fnames = os.listdir(train_cats_dir)\n",
    "train_dog_fnames = os.listdir(train_dogs_dir)\n",
    "\n",
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
    "                                   rotation_range = 40,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size = 20,\n",
    "                                                    class_mode = 'binary', \n",
    "                                                    target_size = (150, 150))     \n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
    "                                                          batch_size  = 20,\n",
    "                                                          class_mode  = 'binary', \n",
    "                                                          target_size = (150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w3OftGS5LyB8"
   },
   "outputs": [],
   "source": [
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output)\n",
    "x = layers.Dense(644, activation='swish')(x)\n",
    "x = layers.Dropout(0.33)(x)\n",
    "x = layers.Dense(644, activation='swish')(x)\n",
    "x = layers.Dropout(0.33)(x) \n",
    "x = layers.Dense(124, activation='swish')(x) \n",
    "x = layers.Dropout(0.33)(x)    \n",
    "x = layers.Dense(62, activation='swish')(x) \n",
    "x = layers.Dropout(0.33)(x)               \n",
    "x = layers.Dense(1, activation='sigmoid')(x) \n",
    "\n",
    "model1 = Model(pre_trained_model.input, x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TvILwlUnMP7j"
   },
   "outputs": [],
   "source": [
    "#next, create a custom optimizer\n",
    "optimizer1 = RMSprop(lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AfhNTJPoMQoV"
   },
   "outputs": [],
   "source": [
    "model1.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer1,\n",
    "              metrics=['mae','accuracy', precision])\n",
    "\n",
    "history1 = model1.fit(train_generator, \n",
    "                      validation_data = validation_generator,\n",
    "                      epochs=40, \n",
    "                      steps_per_epoch = 100,\n",
    "                      validation_steps = 50,\n",
    "                      verbose = 2,\n",
    "                       callbacks=[callbacks])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CatandDogPicturesClassification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
